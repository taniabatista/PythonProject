{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------- Import Modules  ---------\n",
    "import os\n",
    "#from tqdm import tqdm #not found\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import radviz\n",
    "\n",
    "# 2ND: ADD NEW SECTOR\n",
    "# --------- Imort Modules  ---------\n",
    "# import tqdm -- pip install tqdm\n",
    "import os\n",
    "#from tqdm import tqdm #not found\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import radviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tania\\OneDrive - Universidad de Alcala\\PythonProject\\all_stocks_5yr.csv\n"
     ]
    }
   ],
   "source": [
    "# --------- Download stock table from Kaggle ---------\n",
    "# www.kaggle.com/camnugent/sandp500/downloads/all_stocks_5yr.csv\n",
    "\n",
    "\n",
    "# 1 --------- Automatically load correct file in folder path ---------\n",
    "#path = '\\python_project\\all_stocks_5yr.csv'\n",
    "pwd = os.getcwd()\n",
    "path = pwd+'\\\\'+'all_stocks_5yr.csv'\n",
    "print(path)\n",
    "sp500 = pd.read_csv(path , delimiter=',',decimal='.', header=0)\n",
    "sp_original_dataframe = pd.DataFrame(sp500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND: ADD NEW SECTOR\n",
    "# --------- Download stock table from Kaggle ---------\n",
    "# www.kaggle.com/camnugent/sandp500/downloads/all_stocks_5yr.csv\n",
    "\n",
    "\n",
    "# 1 --------- Automatically load correct file in folder path ---------\n",
    "#path = '\\python_project\\all_stocks_5yr.csv'\n",
    "pwd = os.getcwd()\n",
    "path = pwd+'\\\\'+'all_stocks_5yr.csv'\n",
    "print(path)\n",
    "sp500 = pd.read_csv(path , delimiter=',',decimal='.', header=0)\n",
    "sp = pd.DataFrame(sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dropping duplicate rows... \n",
      "            Date   Open   High    Low  Close     Volume  Name\n",
      "0     2012-08-13  92.29  92.59  91.74  92.40  2075391.0   MMM\n",
      "1258  2012-08-13  32.93  33.02  32.84  33.00  5290056.0   ABT\n",
      "2516  2012-12-10  37.00  37.00  34.91  35.00   749378.0  ABBV\n",
      "3693  2012-08-13  61.27  61.55  60.94  61.50  1436939.0   ACN\n",
      "4951  2012-08-13  11.59  11.60  11.34  11.52  5846685.0  ATVI\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2 --------- To the number of rows and records, drop the duplicates  ---------\n",
    "print(\"\\n Dropping duplicate rows... \")\n",
    "sp_1_stock_per_row = sp_original_dataframe.drop_duplicates(['Name'])\n",
    "print(sp_1_stock_per_row.head())\n",
    "print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND: ADD NEW SECTOR\n",
    "# 2 --------- To the number of rows and records, drop the duplicates  ---------\n",
    "print(\"\\n Dropping duplicate rows... \")\n",
    "sp = sp.drop_duplicates(['Name'])\n",
    "print(sp.head())\n",
    "print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " After adding a column \n",
      "\n",
      "            Date   Open   High    Low  Close     Volume  Name Sector\n",
      "0     2012-08-13  92.29  92.59  91.74  92.40  2075391.0   MMM    MMM\n",
      "1258  2012-08-13  32.93  33.02  32.84  33.00  5290056.0   ABT    ABT\n",
      "2516  2012-12-10  37.00  37.00  34.91  35.00   749378.0  ABBV   ABBV\n",
      "3693  2012-08-13  61.27  61.55  60.94  61.50  1436939.0   ACN    ACN\n",
      "4951  2012-08-13  11.59  11.60  11.34  11.52  5846685.0  ATVI   ATVI\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tania\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 3 --------- Add a new column named \"Sector\" which will match stock's Name ------------\n",
    "sp_1_stock_per_row['Sector'] = sp_1_stock_per_row.Name\n",
    "print (\"\\n After adding a column \\n\")\n",
    "print(sp_1_stock_per_row.head())\n",
    "print(\"-------------------------------------------------\")\n",
    "print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND: ADD NEW SECTOR\n",
    "# 3 --------- Add a new column named \"Sector\" which will match stock's Name ------------\n",
    "sp['Sector'] = sp.Name\n",
    "print (\"\\n After adding a column \\n\")\n",
    "print(sp.head(3))\n",
    "print(\"-------------------------------------------------\")\n",
    "print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Duplicates..... \n",
      "\n",
      "length of rows:  503\n"
     ]
    }
   ],
   "source": [
    "# 4 ----------- Save the DataFrame to a NEW file: df_plus_sector_file.csv -----------\n",
    "print (\"Dropping Duplicates..... \\n\")\n",
    "sp_1_stock_per_row.drop_duplicates(['Name'])\n",
    "name = sp_1_stock_per_row.Name.unique()\n",
    "print (\"length of rows: \", len(sp_1_stock_per_row.Low))\n",
    "sp_1_stock_per_row.to_csv('df_plus_sector_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND: ADD NEW SECTOR\n",
    "# 4 ----------- Save the DataFrame to df_with_sector.csv -----------\n",
    "print (\"Dropping Duplicates..... \\n\")\n",
    "sp.drop_duplicates(['Name'])\n",
    "name = sp.Name.unique()\n",
    "print (\"length of rows: \",len(sp.Low))\n",
    "sp.to_csv('df_with_sector.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of rows :  503\n",
      "   Unnamed: 0  Unnamed: 0.1        Date   Open   High    Low  Close  \\\n",
      "0           0             0  2012-08-13  92.29  92.59  91.74  92.40   \n",
      "1           1          1258  2012-08-13  32.93  33.02  32.84  33.00   \n",
      "2           2          2516  2012-12-10  37.00  37.00  34.91  35.00   \n",
      "3           3          3693  2012-08-13  61.27  61.55  60.94  61.50   \n",
      "4           4          4951  2012-08-13  11.59  11.60  11.34  11.52   \n",
      "\n",
      "      Volume  Name Sector  \n",
      "0  2075391.0   MMM    MMM  \n",
      "1  5290056.0   ABT    ABT  \n",
      "2   749378.0  ABBV   ABBV  \n",
      "3  1436939.0   ACN    ACN  \n",
      "4  5846685.0  ATVI   ATVI  \n"
     ]
    }
   ],
   "source": [
    "# 5 ----------- Now load the df_with_sector.csv file -----------\n",
    "#path = '\\python_project\\df_plus_sector.csv'\n",
    "path_df_plus_sector_file = pwd+'\\\\'+'df_plus_sector_file.csv'\n",
    "read_dataframe = pd.read_csv(path_df_plus_sector_file, delimiter=',', decimal='.', header=0)\n",
    "sp_1_stock_per_row_with_sector = pd.DataFrame(read_dataframe)\n",
    "print (\"length of rows : \", len(sp_1_stock_per_row_with_sector.Low))\n",
    "print(sp_1_stock_per_row_with_sector.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND: ADD NEW SECTOR\n",
    "# 5 ----------- Now load the df_with_sector.csv file -----------\n",
    "#path = '\\python_project\\df_with_sector.csv'\n",
    "path = pwd+'\\\\'+'df_with_sector.csv'\n",
    "sp500 = pd.read_csv(path , delimiter=',',decimal='.', header=0)\n",
    "sp = pd.DataFrame(sp500)\n",
    "print (\"length of rows : \", len(sp.Low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector Column: \n",
      "0               Industrials\n",
      "1               Health Care\n",
      "2               Health Care\n",
      "3    Information Technology\n",
      "4    Information Technology\n",
      "Name: Sector, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Stock's Name Column: \n",
      "0             3M Company\n",
      "1    Abbott Laboratories\n",
      "2                 AbbVie\n",
      "3          Accenture plc\n",
      "4    Activision Blizzard\n",
      "Name: Name, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6 ----------- Download constituents-financials.csv file from GitHub ----------- \n",
    "# https://github.com/datasets/s-and-p-500-companies/blob/master/data/constituents-financials.csv \n",
    "path_constituents_fin = pwd+'\\\\'+'constituents-financials.csv'\n",
    "read_path_cons_file= pd.read_csv(path_constituents_fin)\n",
    "external_constituents_dataframe = pd.DataFrame(read_path_cons_file)\n",
    "# ----------- Print only the Sector column ----------- \n",
    "print (\"Sector Column: \")\n",
    "print (external_constituents_dataframe.Sector.head())\n",
    "print (\"\\n\\n\")\n",
    "# ----------- Print only the Name column -----------\n",
    "print (\"Stock's Name Column: \")\n",
    "print (external_constituents_dataframe.Name.head())\n",
    "print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND: ADD NEW SECTOR\n",
    "# 6 ----------- Download and print constituents-financials.csv file from GitHub ----------- \n",
    "# https://github.com/datasets/s-and-p-500-companies/blob/master/data/constituents-financials.csv \n",
    "path1 = pwd+'\\\\'+'constituents-financials.csv'\n",
    "consti = pd.read_csv(path1)\n",
    "cn = pd.DataFrame(consti)\n",
    "print (cn.Sector.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 ----------- Assign the External file's Sector to our original dataframe for each Stock Symbol -----------\n",
    "for i in range(len(sp_1_stock_per_row_with_sector.Name)):\n",
    "    for k in range(len(external_constituents_dataframe.Name)):\n",
    "        if external_constituents_dataframe['Name'][k] == sp_1_stock_per_row_with_sector['Name'][i]:\n",
    "            sp_1_stock_per_row_with_sector['Sector'][i] = external_constituents_dataframe['Sector'][k]\n",
    "\n",
    "#del sp_1_stock_per_row_with_sector['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND: ADD NEW SECTOR\n",
    "# 7 ----------- Assign the Sector to the Sector Column for each Stock Symbol -----------\n",
    "for i in range(len(sp.Name)):\n",
    "    #print i\n",
    "    for k in range(len(cn.Symbol)):\n",
    "        if cn.Symbol[k] == sp.Name[i]:\n",
    "            sp['Sector'][i] = cn.Sector[k]\n",
    "\n",
    "del sp['Unnamed: 0']\n",
    "print(sp.head(5))\n",
    "file_name = 'Sector_Name_Output.csv'\n",
    "print (\"Process Complete\")\n",
    "sp.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Print Results -----------\n",
    "print(sp_1_stock_per_row_with_sector.head())\n",
    "file_name = 'Sector_Name_Output.csv'\n",
    "print (\"Process Complete\")\n",
    "sp_1_stock_per_row_with_sector.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#FIRST dataframe. column to replace\n",
    "length_at_registration_dataframe.leaselength_registration\n",
    "\n",
    "\n",
    "\n",
    "#SECOND replacer dataframe\n",
    "codes_idlength_dataframe.leaselengthyears\n",
    "codes_idlength_dataframe.id_leaselength\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
